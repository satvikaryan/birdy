{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import os\n",
    "\n",
    "def manipulate(data, noise_factor):\n",
    "    noise = np.random.randn(len(data))\n",
    "    augmented_data = data + noise_factor * noise\n",
    "    # Cast back to same data type\n",
    "    augmented_data = augmented_data.astype(type(data[0]))\n",
    "    return augmented_data\n",
    "\n",
    "def create_datasets(source_file, output_folder, label, num_datasets):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for i in range(num_datasets):\n",
    "        data, sampling_rate = librosa.load(source_file, sr=None)\n",
    "        noise_factor = np.random.uniform(0.0, 0.15)\n",
    "        augmented_data = manipulate(data, noise_factor)\n",
    "        output_file = os.path.join(output_folder, f\"{label}_{i+1}_noise_{noise_factor:.2f}.wav\")\n",
    "        soundfile.write(output_file, augmented_data, sampling_rate)\n",
    "        print(f\"{label.capitalize()} dataset {i+1} created with noise factor: {noise_factor:.2f}\")\n",
    "\n",
    "# Source files for dot and dash\n",
    "dot_source_file = \"dot_new.wav\"\n",
    "dash_source_file = \"dash_new.wav\"\n",
    "\n",
    "# Output folders for dot and dash datasets\n",
    "dot_output_folder = \"dot\"\n",
    "dash_output_folder = \"dash\"\n",
    "\n",
    "# Number of datasets for dot and dash\n",
    "num_datasets = 3000\n",
    "\n",
    "# Create dot datasets\n",
    "create_datasets(dot_source_file, dot_output_folder, \"dot\", num_datasets)\n",
    "\n",
    "# Create dash datasets\n",
    "create_datasets(dash_source_file, dash_output_folder, \"dash\", num_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Function to extract features from audio files\n",
    "def extract_features(audio_file):\n",
    "    data, sr = librosa.load(audio_file, sr=None)\n",
    "    # Example feature extraction, you can add more features\n",
    "    features = [\n",
    "        np.mean(librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13).T, axis=0),\n",
    "        np.mean(librosa.feature.chroma_stft(y=data, sr=sr).T, axis=0)\n",
    "    ]\n",
    "    return np.concatenate(features)\n",
    "\n",
    "# Path to the directories containing dash and dot audio files\n",
    "dash_folder = \"dash\"\n",
    "dot_folder = \"dot\"\n",
    "\n",
    "# Collect features and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Collect features and labels for dash audio files\n",
    "for file in os.listdir(dash_folder):\n",
    "    if file.endswith(\".wav\"):\n",
    "        features = extract_features(os.path.join(dash_folder, file))\n",
    "        X.append(features)\n",
    "        y.append(\"dash\")\n",
    "\n",
    "# Collect features and labels for dot audio files\n",
    "for file in os.listdir(dot_folder):\n",
    "    if file.endswith(\".wav\"):\n",
    "        features = extract_features(os.path.join(dot_folder, file))\n",
    "        X.append(features)\n",
    "        y.append(\"dot\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_train = rf_classifier.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "\n",
    "y_pred_test = rf_classifier.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "# Save the trained model to a file\n",
    "model_filename = \"audio_classifier_model.pkl\"\n",
    "joblib.dump(rf_classifier, model_filename)\n",
    "print(\"Model saved to\", model_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting with audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clip 1: dash\n",
      "Clip 2: dash\n",
      "Clip 3: dot\n",
      "Clip 4: dot\n",
      "Clip 5: dash\n",
      "Clip 6: dot\n",
      "Clip 7: dot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model_filename = \"audio_classifier_model.pkl\"\n",
    "rf_classifier = joblib.load(model_filename)\n",
    "\n",
    "# Function to extract features from a 1-second audio clip\n",
    "def extract_features_clip(data, sr):\n",
    "    # Example feature extraction, you can add more features\n",
    "    features = [\n",
    "        np.mean(librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13).T, axis=0),\n",
    "        np.mean(librosa.feature.chroma_stft(y=data, sr=sr).T, axis=0)\n",
    "    ]\n",
    "    return np.concatenate(features)\n",
    "\n",
    "# Function to split an audio file into 1-second clips\n",
    "def split_audio_file(audio_file):\n",
    "    data, sr = librosa.load(audio_file, sr=None)\n",
    "    clip_length = sr  # 1 second clip\n",
    "    clips = []\n",
    "    for i in range(0, len(data), clip_length):\n",
    "        clip = data[i:i+clip_length]\n",
    "        if len(clip) == clip_length:  # Ensure all clips are of the same length\n",
    "            clips.append(clip)\n",
    "    return np.array(clips), sr\n",
    "\n",
    "# Function to classify audio clips as dash or dot\n",
    "def classify_audio_clips(clips, sr):\n",
    "    predictions = []\n",
    "    for clip in clips:\n",
    "        features = extract_features_clip(clip, sr)\n",
    "        prediction = rf_classifier.predict([features])[0]\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "# Path to the audio file\n",
    "audio_file = \"input1.wav\"\n",
    "\n",
    "# Split the audio file into 1-second clips\n",
    "clips, sr = split_audio_file(audio_file)\n",
    "\n",
    "# Classify each clip\n",
    "predictions = classify_audio_clips(clips, sr)\n",
    "\n",
    "# Print the predictions\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Clip {i+1}: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attempt for real time predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for audio...\n",
      "Prediction 1: dot\n",
      "Prediction 2: dot\n",
      "Prediction 3: dot\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyaudio\n",
    "import librosa\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model_filename = \"audio_classifier_model.pkl\"\n",
    "rf_classifier = joblib.load(model_filename)\n",
    "\n",
    "# Function to extract features from a 1-second audio clip\n",
    "def extract_features_clip(data, sr):\n",
    "    # Example feature extraction, you can add more features\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13)\n",
    "    chroma = librosa.feature.chroma_stft(y=data, sr=sr)\n",
    "    # Reshape or flatten features to ensure they are 2-dimensional\n",
    "    if len(mfccs.shape) > 1:\n",
    "        mfccs = np.mean(mfccs.T, axis=0)\n",
    "    if len(chroma.shape) > 1:\n",
    "        chroma = np.mean(chroma.T, axis=0)\n",
    "    return np.concatenate([mfccs, chroma])\n",
    "\n",
    "# Function to classify a 1-second audio clip\n",
    "def classify_clip(data, sr):\n",
    "    data_float = data.astype(np.float32) / 32768.0  # Convert to floating-point\n",
    "    features = extract_features_clip(data_float, sr)\n",
    "    prediction = rf_classifier.predict([features])[0]\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# Callback function for audio stream processing\n",
    "def audio_callback(in_data, frame_count, time_info, status):\n",
    "    global audio_buffer, frames_per_buffer, sampling_rate, predictions_made, max_predictions\n",
    "    audio_data = np.frombuffer(in_data, dtype=np.int16)\n",
    "    audio_buffer.extend(audio_data)\n",
    "    while len(audio_buffer) >= sampling_rate:\n",
    "        clip = np.array(audio_buffer[:sampling_rate])\n",
    "        audio_buffer = audio_buffer[sampling_rate:]\n",
    "        prediction = classify_clip(clip, sampling_rate)\n",
    "        print(f\"Prediction {predictions_made + 1}: {prediction}\")\n",
    "        predictions_made += 1\n",
    "        if predictions_made >= max_predictions:\n",
    "            print(\"Maximum predictions reached. Stopping stream.\")\n",
    "            stream.stop_stream()\n",
    "            break\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "# Parameters\n",
    "sampling_rate = 44100\n",
    "channels = 1\n",
    "frames_per_buffer = 1024\n",
    "max_predictions = 10  # Make 10 predictions in 10 seconds\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open stream using callback\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "                channels=channels,\n",
    "                rate=sampling_rate,\n",
    "                input=True,\n",
    "                frames_per_buffer=frames_per_buffer,\n",
    "                stream_callback=audio_callback)\n",
    "\n",
    "print(\"Listening for audio...\")\n",
    "\n",
    "# Initialize variables\n",
    "audio_buffer = []  # Initialize audio buffer\n",
    "predictions_made = 0\n",
    "\n",
    "# Start stream\n",
    "stream.start_stream()\n",
    "\n",
    "# Wait for stream to finish\n",
    "try:\n",
    "    while stream.is_active():\n",
    "        pass\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Stop stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "# Close PyAudio\n",
    "p.terminate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
